{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Faculty Demographic Data from IPEDS\n",
    "\n",
    "This script queries [US IPEDS MS Access files](https://nces.ed.gov/ipeds/use-the-data/download-access-database) and generates datasets for analyzing diversity among tenured faculty.\n",
    "\n",
    "Requirements:\n",
    "* [mdb-tools](https://github.com/mdbtools/mdbtools)\n",
    "\n",
    "Tables of note:\n",
    "* `Directory Information`: contains directory information with name, address, city, state, zipcode, etc\n",
    "* `Response Status`: did the institution respond, or were the data imputed?\n",
    "* `Full-time instructional/research/public service  staff, by faculty and tenure status, academic rank, race/ethnicity, and gender (Degree-granting institutions): Fall YYYY`: Multiple records per institution. \n",
    "  * CAUTION:  Reporting Human resource data by race/ethnicity and gender is optional in even-numbered years, so many institutions will not have data.\n",
    "  * Beginning with 2016 reporting human resource data by race/ethnicity and gender is mandatory annually.\n",
    "* New hires by occupational category, race/ethnicity, and gender (Degree-granting institutions):  Fall YYYY: Multiple records per institution\n",
    "\n",
    "Other data used:\n",
    "* CCIHE2018-PublicData.xlsx: [Carnegie Classification Data](https://carnegieclassifications.iu.edu/downloads.php)\n",
    "* mrc_table10.csv: [College Level Characteristics from the Opportunity Insights College Scorecard](https://opportunityinsights.org/wp-content/uploads/2018/04/Codebook-MRC-Table-10.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "is_executing": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LOAD LIBRARIES\n",
    "from plotnine import ggplot, aes, geom_line\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import glob, os, sys, subprocess # for accessing mdb-tools\n",
    "#import simplejson as json\n",
    "import csv\n",
    "import codecs\n",
    "import datetime\n",
    "import copy\n",
    "import re #for string matching\n",
    "\n",
    "##load simplejson to fix error\n",
    "##!pip install simplejson as json\n",
    "import subprocess\n",
    "subprocess.check_call(['pip', 'install', 'simplejson==3.19.3'])\n",
    "\n",
    "data_path = r\"C:\\Users\\jnajab.AD\\OneDrive - AAAS\\Documents\\SEAChange\\Faculty Parity Project\\US-Faculty-Diversity-Projections-main\\data\\IPEDS_DATA_FOLDER\"\n",
    "\n",
    "## data_path = \"C:\\\\Users\\\\jnajab.AD\\\\OneDrive - AAAS\\\\Documents\\\\SEAChange\\\\Faculty Parity Project\\\\US-Faculty-Diversity-Projections-main\\\\data\\\\IPEDS_DATA_FOLDER\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Define Table Names - hand checked from IPEDSYYYYYYTablesDoc.xlsx for each year\n",
    "table_info = {\n",
    "    \"2004-05\":{\n",
    "        \"directory\":\"HD2004\",\n",
    "        \"faculty_demographics\":\"S2004_F\",\n",
    "        \"rank_columns\": \"2004\" # which rank categories \n",
    "    },\n",
    "    \"2005-06\":{\n",
    "        \"directory\":\"HD2005\",\n",
    "        \"faculty_demographics\":\"S2005_F\",\n",
    "        \"rank_columns\": \"2004\" # which rank categories \n",
    "    },\n",
    "    \"2006-07\":{\n",
    "        \"directory\":\"HD2006\",\n",
    "        \"faculty_demographics\":\"S2006_F\",\n",
    "        \"rank_columns\": \"2004\" # which rank categories \n",
    "    },\n",
    "    \"2007-08\":{\n",
    "        \"directory\":\"HD2007\",\n",
    "        \"faculty_demographics\":\"S2007_F\",\n",
    "        \"rank_columns\": \"2004\" # which rank categories \n",
    "    },\n",
    "    \"2008-09\":{\n",
    "        \"directory\":\"HD2008\",\n",
    "        \"faculty_demographics\":\"S2008_F\",\n",
    "        \"rank_columns\": \"2004\" # which rank categories \n",
    "    },\n",
    "    \"2009-10\":{\n",
    "        \"directory\":\"HD2009\",\n",
    "        \"faculty_demographics\":\"S2009_F\",\n",
    "        \"rank_columns\": \"2004\" # which rank categories \n",
    "    },\n",
    "    \"2010-11\":{\n",
    "        \"directory\":\"HD2010\",\n",
    "        \"faculty_demographics\":\"S2010_F\",\n",
    "        \"rank_columns\": \"2004\" # which rank categories \n",
    "    },\n",
    "    \"2011-12\":{\n",
    "        \"directory\":\"HD2011\",\n",
    "        \"faculty_demographics\":\"S2011_F\",\n",
    "        \"rank_columns\": \"2004\" # which rank categories \n",
    "    },\n",
    "    \"2012-13\":{\n",
    "        \"directory\":\"HD2012\",\n",
    "        \"faculty_demographics\":\"S2012_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "    \"2013-14\":{\n",
    "        \"directory\":\"HD2013\",\n",
    "        \"faculty_demographics\":\"S2013_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "    \"2014-15\":{\n",
    "        \"directory\":\"HD2014\",\n",
    "        \"faculty_demographics\":\"S2014_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "    \"2015-16\":{\n",
    "        \"directory\":\"HD2015\",\n",
    "        \"faculty_demographics\":\"S2015_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "    \"2016-17\":{\n",
    "        \"directory\":\"HD2016\",\n",
    "        \"faculty_demographics\":\"S2016_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "    \"2017-18\":{\n",
    "        \"directory\":\"HD2017\",\n",
    "        \"faculty_demographics\":\"S2017_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "    \"2018-19\":{\n",
    "        \"directory\":\"HD2018\",\n",
    "        \"faculty_demographics\":\"S2018_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "    \"2019-20\":{\n",
    "        \"directory\":\"HD2019\",\n",
    "        \"faculty_demographics\":\"S2019_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "    \"2020-21\":{\n",
    "        \"directory\":\"HD2020\",\n",
    "        \"faculty_demographics\":\"S2020_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "        \"2021-22\":{\n",
    "        \"directory\":\"HD2021\",\n",
    "        \"faculty_demographics\":\"S2021_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    },\n",
    "        \"2022-23\":{\n",
    "        \"directory\":\"HD2022\",\n",
    "        \"faculty_demographics\":\"S2022_IS\",\n",
    "        \"rank_columns\": \"2012\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\jnajab.AD\\\\OneDrive - AAAS\\\\Documents\\\\SEAChange\\\\Faculty Parity Project\\\\US-Faculty-Diversity-Projections-main\\\\data\\\\IPEDS_DATA_FOLDER',\n",
       " 'C:\\\\Users\\\\jnajab.AD\\\\OneDrive - AAAS\\\\Documents\\\\SEAChange\\\\Faculty Parity Project\\\\US-Faculty-Diversity-Projections-main\\\\data\\\\IPEDS_DATA_FOLDER']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## folders that we need to store but which\n",
    "## shouldn't be included in the data. List\n",
    "## folders representing provisional data for which\n",
    "## we now have final data\n",
    "\n",
    "folders_to_omit = [\"IPEDS_2019-20_Provisional\"]\n",
    "\n",
    "folders = [x for x in glob.glob(data_path + \"*\") if x.find(\"zip\")==-1 \n",
    "#folders = [x for x in glob.glob(IPEDS_DATA_FOLDER + \"*\") if x.find(\"zip\")==-1 \n",
    "\n",
    "           and x.find(\"csv\")==-1 and x.find(\"outputs\")==-1 \n",
    "           and x.find(\"xlsx\")==-1 and x.find(\"numbers\")==-1]\n",
    "\n",
    "data_folders = [r\"C:\\Users\\jnajab.AD\\OneDrive - AAAS\\Documents\\SEAChange\\Faculty Parity Project\\US-Faculty-Diversity-Projections-main\\data\\IPEDS_DATA_FOLDER\"] #######INSERT DATA PATH\n",
    "\n",
    "for folder in folders:\n",
    "    include = True\n",
    "    for o in folders_to_omit:\n",
    "        if folder.find(o)!=-1:\n",
    "            include = False\n",
    "    if(include):\n",
    "        data_folders.append(folder)\n",
    "        #IPEDS_DATA_FOLDER.append(folder)\n",
    "data_folders\n",
    "#IPEDS_DATA_FOLDER.append(folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Institution Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DATA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     22\u001b[0m year \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*?IPEDS_(.*?)_\u001b[39m\u001b[38;5;124m\"\u001b[39m,folder)\u001b[38;5;241m.\u001b[39mgroups()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 23\u001b[0m table \u001b[38;5;241m=\u001b[39m table_info[year]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m## load file\u001b[39;00m\n\u001b[0;32m     26\u001b[0m filename \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(folder\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/*.accdb\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DATA'"
     ]
    }
   ],
   "source": [
    "## Create institution object \n",
    "def institution():\n",
    "    return {\n",
    "        \"UNITID\":None, #ID\n",
    "        \"INSTNM\": None, #Name (some overlap),\n",
    "        \"STABBR\": None, #State Abbreviation\n",
    "        \n",
    "        ## the key for these are academic year, such as \"2013-14\"\n",
    "        \"directory_year\": {},\n",
    "        \"faculty_demographics_year\": {}\n",
    "    }\n",
    "\n",
    "institutions = defaultdict(institution)\n",
    "\n",
    "\n",
    "## iterate through each folder / year and fetch metadata\n",
    "## on the folder names to examine, per year\n",
    "for folder in data_folders:\n",
    "#for folder in IPEDS_DATA_FOLDER:\n",
    "    if folder.find(\"csv\") >-1 or folder.find(\"xlsx\") >-1 or folder.find(\"outputs\")>-1:\n",
    "        continue\n",
    "    year = re.match(\".*?IPEDS_(.*?)_\",folder).groups()[0]\n",
    "    table = table_info[year]\n",
    "    \n",
    "    ## load file\n",
    "    filename = glob.glob(folder+\"/*.accdb\")[0]\n",
    "    directory = subprocess.Popen(['mdb-export', filename, table['directory']], stdout=subprocess.PIPE).communicate()[0].decode()\n",
    "    \n",
    "    counter = 0\n",
    "    for row in csv.DictReader(directory.split(\"\\n\")):\n",
    "        institutions[row['UNITID']]['UNITID'] = row['UNITID']\n",
    "        institutions[row['UNITID']]['INSTNM'] = row['INSTNM']\n",
    "        institutions[row['UNITID']]['STABBR'] = row['STABBR']\n",
    "        institutions[row['UNITID']]['directory_year'][year] = row\n",
    "        counter += 1\n",
    "    print(\"{0}: Loaded {1} institutions\".format(year, counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Student Demographic Records (to identify primarily-white institutions)\n",
    "PWI doesn't have an agreed-on definition.  I found a graduate thesis that labeled an institution a PWI if it was not listed as an HBCU or HSI. I plan to label institutions as a PWI based on the percentage of white students reported in the most recent datafile. Institutions with more than 50% white students will be labeled PWIs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m year \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*?IPEDS_(.*?)_\u001b[39m\u001b[38;5;124m\"\u001b[39m,folder)\u001b[38;5;241m.\u001b[39mgroups()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#year = re.match(\"/IPEDS_DATA_FOLDER/.*?IPEDS_(.*?)_\",folder).groups()[0]\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m filename \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(folder\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/*.accdb\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m deriv_variable_tablename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDRVEF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m year[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m## load raw table text into table_data\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pct_white_column = \"PCTENRWH\"\n",
    "\n",
    "## set up variables for loading the most recent table\n",
    "folder = [folder for folder in data_folders if folder.find(\"csv\") ==-1 and folder.find(\"xlsx\") ==-1 and folder.find(\"outputs\") == -1][-1]\n",
    "#folder = [folder for folder in IPEDS_DATA_FOLDER if folder.find(\"csv\") ==-1 and folder.find(\"xlsx\") ==-1 and folder.find(\"outputs\") == -1][-1]\n",
    "year = re.match(\".*?IPEDS_(.*?)_\",folder).groups()[0]\n",
    "#year = re.match(\"/IPEDS_DATA_FOLDER/.*?IPEDS_(.*?)_\",folder).groups()[0]\n",
    "\n",
    "filename = glob.glob(folder+\"/*.accdb\")[0]\n",
    "deriv_variable_tablename = \"DRVEF\" + year[0:4]\n",
    "\n",
    "## load raw table text into table_data\n",
    "table_data = subprocess.Popen(['mdb-export', filename, deriv_variable_tablename], stdout=subprocess.PIPE).communicate()[0].decode()\n",
    "\n",
    "## load table_data into a dict for determining primarily-white-institutions\n",
    "institution_pwi = {}\n",
    "for row in csv.DictReader(table_data.split(\"\\n\")):\n",
    "    # set UNITID key, since capitalization is inconsistent between years\n",
    "    unitid_key = \"UNITID\"\n",
    "    if(unitid_key not in row.keys()):\n",
    "        unitid_key = \"UnitID\"\n",
    "    unitid = row[unitid_key]\n",
    "    \n",
    "    if(pct_white_column in row.keys()):\n",
    "        pct_white = int(row[pct_white_column])\n",
    "    else:\n",
    "        pct_white = None\n",
    "    institution_pwi[unitid] = pct_white\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Faculty Demographics Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in data_folders:\n",
    "    if folder.find(\"csv\") >-1 or folder.find(\"xlsx\") >-1 or folder.find(\"outputs\")>-1:\n",
    "        continue\n",
    "    year = re.match(\".*?IPEDS_(.*?)_\",folder).groups()[0]\n",
    "    table = table_info[year]\n",
    "    \n",
    "    ## load file\n",
    "    filename = glob.glob(folder+\"/*.accdb\")[0]\n",
    "    table_data = subprocess.Popen(['mdb-export', filename, table['faculty_demographics']], stdout=subprocess.PIPE).communicate()[0].decode()\n",
    "    \n",
    "    \n",
    "    counter = 0\n",
    "    for row in csv.DictReader(table_data.split(\"\\n\")):\n",
    "        \n",
    "        # set UNITID key, since capitalization is inconsistent between years\n",
    "        unitid_key = \"UNITID\"\n",
    "        if(unitid_key not in row.keys()):\n",
    "            unitid_key = \"UnitID\"\n",
    "        unitid = row[unitid_key]\n",
    "        \n",
    "        if year not in institutions[unitid]['faculty_demographics_year'].keys():\n",
    "            institutions[unitid]['faculty_demographics_year'][year] = []\n",
    "        institutions[unitid]['faculty_demographics_year'][year].append(row)\n",
    "        counter += 1\n",
    "        \n",
    "    print(\"{0}: Loaded {1} faculty demographics records\".format(year, counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert IPEDS columns to human-readable columns\n",
    "\n",
    "2004-2005 codes:\n",
    "* **ARANK:** \n",
    "  * 22: *Total full-time faculty*\n",
    "  * 1: Total full-time faculty, Tenured, Professors \n",
    "  * 2: Total full-time faculty, Tenured, Associate professors\n",
    "  * 3: Total full-time faculty, Tenured, Assistant professors\n",
    "  * <del> 4: Total full-time faculty, Tenured, Instructors</del>\n",
    "  * <del> 5: Total full-time faculty, Tenured, Lecturers</del>\n",
    "  * 6: <del> Total full-time faculty, Tenured, No academic rank</del>\n",
    "  * 7: *Total full-time faculty, Tenured total*\n",
    "  * 8: Total full-time faculty, Non-tenured on tenure track, Professors\n",
    "  * 9: Total full-time faculty, Non-tenured on tenure track, Associate professors\n",
    "  * 10: Total full-time faculty, Non-tenured on tenure track, Assistant professors\n",
    "  * <del> 11: Total full-time faculty, Non-tenured on tenure track, Instructors</del>\n",
    "  * <del> 12: Total full-time faculty, Non-tenured on tenure track, Lecturers</del>\n",
    "  * 13: <del> Total full-time faculty, Non-tenured on tenure track, No academic rank</del>\n",
    "  * 14: *Total full-time faculty, Non-tenured on tenure track total*\n",
    "\n",
    "* **Staff Columns:**\n",
    "    * STAFF19\tAmerican Indian or Alaska Native total\n",
    "    * STAFF20\tAsian or Pacific Islander total\n",
    "    * STAFF21\tHispanic total\n",
    "    * STAFF22\tWhite non-Hispanic total\n",
    "    * STAFF01\tNonresident alien men\n",
    "    * STAFF02\tNonresident alien women\n",
    "    * STAFF03\tBlack non-Hispanic men\n",
    "    * STAFF04\tBlack non-Hispanic women\n",
    "    * STAFF05\tAmerican Indian or Alaska Native men\n",
    "    * STAFF06\tAmerican Indian or Alaska Native women\n",
    "    * STAFF07\tAsian or Pacific Islander men\n",
    "    * STAFF08\tAsian or Pacific Islander women\n",
    "    * STAFF09\tHispanic men\n",
    "    * STAFF10\tHispanic women\n",
    "    * STAFF11\tWhite non-Hispanic men\n",
    "    * STAFF12\tWhite non-Hispanic women\n",
    "    * STAFF13\tRace/ethnicity unknown men\n",
    "    * STAFF14\tRace/ethnicity unknown women\n",
    "    * STAFF15\tGrand total men\n",
    "    * STAFF16\tGrand total women\n",
    "    * STAFF17\tNonresident alien total\n",
    "    * STAFF18\tBlack non-Hispanic  total\n",
    "    * STAFF23\tRace/ethnicity unknown total\n",
    "    * STAFF24\tGrand total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata for Querying Records and Merging Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## since the rows change and the meaning of the integers change\n",
    "## at certain points, I have created these methods and placed\n",
    "## them into a dict so the right method can be called for the\n",
    "## right piece of information, depending on what year the record is from\n",
    "\n",
    "def rank_2004_total_tenured(row):\n",
    "    return row['ARANK']=='7'\n",
    "\n",
    "## non_tenured is different from untenured tenure-track\n",
    "def rank_2004_total_non_tenured(row):\n",
    "    return row['ARANK']=='14'\n",
    "\n",
    "def rank_2004_tenured_full(row):\n",
    "    return row['ARANK']=='1'\n",
    "def rank_2004_tenured_associate(row):\n",
    "    return row['ARANK']=='2'\n",
    "def rank_2004_tenured_assistant(row):\n",
    "    return row['ARANK']=='3'\n",
    "\n",
    "## non_tenured is different from untenured tenure-track\n",
    "def rank_2004_non_tenured_full(row):\n",
    "    return row['ARANK']=='8'\n",
    "## non_tenured is different from untenured tenure-track\n",
    "def rank_2004_non_tenured_associate(row):\n",
    "    return row['ARANK']=='9'\n",
    "## non_tenured is different from untenured tenure-track\n",
    "def rank_2004_non_tenured_assistant(row):\n",
    "    return row['ARANK']=='10'\n",
    "\n",
    "## return empty list for categories that \n",
    "## don't exist in the 2004 data\n",
    "def rank_2004_no_values(row):\n",
    "    return []\n",
    "\n",
    "rank_2004 = {\n",
    "    \"rank_object\":           \"2004\",\n",
    "    \"tenured\":         rank_2004_total_tenured,\n",
    "    \"non_tenured\":     rank_2004_total_non_tenured,\n",
    "    \"un_tenured\":      rank_2004_no_values,\n",
    "\n",
    "    \"tenured_full\":          rank_2004_tenured_full,\n",
    "    \"tenured_associate\":     rank_2004_tenured_associate,\n",
    "    \"tenured_assistant\":     rank_2004_tenured_assistant,\n",
    "    \n",
    "    \"non_tenured_full\":      rank_2004_non_tenured_full,\n",
    "    \"non_tenured_associate\": rank_2004_non_tenured_associate,\n",
    "    \"non_tenured_assistant\": rank_2004_non_tenured_assistant,\n",
    "    \n",
    "    \"un_tenured_full\":       rank_2004_no_values,\n",
    "    \"un_tenured_associate\":  rank_2004_no_values,\n",
    "    \"un_tenured_assistant\":  rank_2004_no_values\n",
    "}\n",
    "\n",
    "## CREATE A DICT FOR HUMAN READABLE COLUMNS\n",
    "\n",
    "# different keys different years for nonresidents\n",
    "# STAFF prefixes are before 2010-11\n",
    "# HR prefixes are from 2010-11 to 2011-12 \n",
    "col_keys = {\"STAFF19\":\"American Indian or Alaska Native total\",\n",
    "             \"HRAIANT\":\"American Indian or Alaska Native total\",\n",
    "\n",
    "             \"STAFF05\":\"American Indian or Alaska Native men\",\n",
    "             \"HRAIANM\":\"American Indian or Alaska Native men\",\n",
    "\n",
    "             \"STAFF06\":\"American Indian or Alaska Native women\",\n",
    "             \"HRAIANW\":\"American Indian or Alaska Native women\",\n",
    "\n",
    "            ## Changes to Black or African American in 2010-11\n",
    "             \"STAFF18\":\"Black non-Hispanic total\",             \n",
    "             \"STAFF03\":\"Black non-Hispanic men\",             \n",
    "             \"STAFF04\":\"Black non-Hispanic women\",\n",
    "\n",
    "             ## Changes to Asian | Native Hawaiian or Other Pacific Islander in 2010-11            \n",
    "             \"STAFF20\":\"Asian or Pacific Islander total\",\n",
    "             \"STAFF07\":\"Asian or Pacific Islander men\",\n",
    "             \"STAFF08\":\"Asian or Pacific Islander women\",\n",
    "\n",
    "             ## Changes to Hispanic or Latino Men in 2010-11\n",
    "             \"STAFF21\":\"Hispanic total\",\n",
    "             \"STAFF09\":\"Hispanic men\",\n",
    "             \"STAFF10\":\"Hispanic women\",\n",
    "\n",
    "             ## Changes to White in 2010-11\n",
    "             \"STAFF22\":\"White non-Hispanic total\",\n",
    "             \"STAFF11\":\"White non-Hispanic men\",             \n",
    "             \"STAFF12\":\"White non-Hispanic women\",\n",
    "\n",
    "             # Race/ethnicity unknown\n",
    "             \"STAFF23\":\"Race/ethnicity unknown total\",\n",
    "             \"HRUNKNT\":\"Race/ethnicity unknown total\",\n",
    "             \n",
    "             \"STAFF13\":\"Race/ethnicity unknown men\",\n",
    "             \"HRUNKNM\":\"Race/ethnicity unknown men\",\n",
    "             \n",
    "             \"STAFF14\":\"Race/ethnicity unknown women\",\n",
    "             \"HRUNKNW\":\"Race/ethnicity unknown women\",\n",
    "             \n",
    "             # Grand Totals\n",
    "             \"STAFF24\":\"Grand total\",\n",
    "             \"HRTOTLT\":\"Grand total\",\n",
    "\n",
    "             \"STAFF15\":\"Grand total men\",\n",
    "             \"HRTOTLM\":\"Grand total men\",\n",
    "             \n",
    "             \"STAFF16\":\"Grand total women\",\n",
    "             \"HRTOTLW\":\"Grand total women\",\n",
    "\n",
    "             # Nonresident alien\n",
    "             \"STAFF17\":\"Nonresident alien total\",\n",
    "             \"HRNRALT\":\"Nonresident alien total\",\n",
    "             \n",
    "             \"STAFF01\":\"Nonresident alien men\", \n",
    "             \"HRNRALM\":\"Nonresident alien men\",\n",
    "             \n",
    "             \"STAFF02\":\"Nonresident alien women\",\n",
    "             \"HRNRALW\":\"Nonresident alien women\",\n",
    "             \n",
    "             \n",
    "             ## Not included datasets before 2010-11\n",
    "             \"HRASIAT\":\"Asian total\",\n",
    "             \"HRASIAM\":\"Asian men\",\n",
    "             \"HRASIAW\":\"Asian women\",\n",
    "             \"HRBKAAT\":\"Black or African American total\",\n",
    "             \"HRBKAAM\":\"Black or African American men\",\n",
    "             \"HRBKAAW\":\"Black or African American women\", \n",
    "             \"HRHISPT\":\"Hispanic or Latino total\",\n",
    "             \"HRHISPM\":\"Hispanic or Latino men\",\n",
    "             \"HRHISPW\":\"Hispanic or Latino women\",\n",
    "             \"HRNHPIT\":\"Native Hawaiian or Other Pacific Islander total\", \n",
    "             \"HRNHPIM\":\"Native Hawaiian or Other Pacific Islander men\", \n",
    "             \"HRNHPIW\":\"Native Hawaiian or Other Pacific Islander women\",\n",
    "             \"HRWHITT\":\"White total\",\n",
    "             \"HRWHITM\":\"White men\",\n",
    "             \"HRWHITW\":\"White women\", \n",
    "             \"HR2MORT\":\"Two or more races total\",\n",
    "             \"HR2MORM\":\"Two or more races men\",\n",
    "             \"HR2MORW\":\"Two or more races women\"  \n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata for Querying Records from 2012-13 through 2018-19Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_2012_total_tenured(row):\n",
    "    return row['ARANK']=='0' and row['SISCAT'] == '200'\n",
    "\n",
    "# un-tenured and on tenure track\n",
    "def rank_2012_total_un_tenured(row):\n",
    "    return row['ARANK']=='0' and row['SISCAT'] == '300'\n",
    "\n",
    "def rank_2012_tenured_full(row):\n",
    "    return row['ARANK']=='1' and row['SISCAT'] == '201'\n",
    "def rank_2012_tenured_associate(row):\n",
    "    return row['ARANK']=='2' and row['SISCAT'] == '202'\n",
    "def rank_2012_tenured_assistant(row):\n",
    "    return row['ARANK']=='3' and row['SISCAT'] == '203'\n",
    "def rank_2012_un_tenured_full(row):\n",
    "    return row['ARANK']=='1' and row['SISCAT'] == '301'\n",
    "def rank_2012_un_tenured_associate(row):\n",
    "    return row['ARANK']=='2' and row['SISCAT'] == '302'\n",
    "def rank_2012_un_tenured_assistant(row):\n",
    "    return row['ARANK']=='3' and row['SISCAT'] == '303'\n",
    "\n",
    "## return empty list for categories that \n",
    "## don't exist in the 2012 data and onward\n",
    "def rank_2012_no_values(row):\n",
    "    return []\n",
    "\n",
    "\n",
    "rank_2012 = {\n",
    "    \"rank_object\":           \"2012\",\n",
    "    \"tenured\":         rank_2012_total_tenured,\n",
    "    \"non_tenured\":     rank_2012_no_values,\n",
    "    \"un_tenured\":      rank_2012_total_un_tenured,\n",
    "\n",
    "    \"tenured_full\":          rank_2012_tenured_full,\n",
    "    \"tenured_associate\":     rank_2012_tenured_associate,\n",
    "    \"tenured_assistant\":     rank_2012_tenured_assistant,\n",
    "        \n",
    "    \"un_tenured_full\":       rank_2012_un_tenured_full,\n",
    "    \"un_tenured_associate\":  rank_2012_un_tenured_associate,\n",
    "    \"un_tenured_assistant\":  rank_2012_un_tenured_assistant,\n",
    "    \n",
    "    ## NOTE: these are actually available\n",
    "    ## but I don't know how well they correspond\n",
    "    ## to how things were collected in the 2004+ period\n",
    "    ## so I'm omitting them to avoid confusion\n",
    "    \"non_tenured_full\":      rank_2012_no_values,\n",
    "    \"non_tenured_associate\": rank_2012_no_values,\n",
    "    \"non_tenured_assistant\": rank_2012_no_values\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data for a Single Institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pull out Cornell for initial prototyping and data validation\n",
    "# institution_match_string = \"Michigan\"\n",
    "\n",
    "# [(x['UNITID'], x['INSTNM']) for x in institutions.values() if x['INSTNM'].find(institution_match_string)!=-1]\n",
    "\n",
    "#institution = institutions['190415']\n",
    "#institution_name = \"Cornell University\"\n",
    "\n",
    "#institution = institutions['186131']\n",
    "#institution_name = 'Princeton University'\n",
    "\n",
    "# institution = institutions['166683']\n",
    "# institution_name = 'Massachusetts Institute of Technology'\n",
    "\n",
    "# institution = institutions['170976']\n",
    "# institution_name = 'University of Michigan-Ann Arbor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch all rows for an institution. Note: this makes heavy\n",
    "# use of globals\n",
    "def rows_for_institution(institution):\n",
    "    \n",
    "    ## for a given university, iterate through the rank rows \n",
    "    ## and collapse them into a single row with many columns\n",
    "    all_rows = []\n",
    "    institution_name = institution['INSTNM']\n",
    "\n",
    "    for year in institution['faculty_demographics_year'].keys():\n",
    "        new_row = {}\n",
    "        new_row['year'] = year\n",
    "        new_row['UNITID'] = institution['UNITID']\n",
    "        new_row['INSTNM'] = institution['INSTNM']\n",
    "        new_row['STABBR'] = institution['STABBR']\n",
    "        if table_info[year]['rank_columns'] =='2004':\n",
    "            rank_object = rank_2004\n",
    "            new_row['schema'] = \"2004\"\n",
    "        else:\n",
    "            rank_object = rank_2012\n",
    "            new_row['schema'] = \"2012\"\n",
    "        \n",
    "#         ## set the grand totals by looking for totals\n",
    "#         rows = [x for x in institution['faculty_demographics_year'][year] if x['ARANK'] =='0' and x['SISCAT'] in ['200', '300']]\n",
    "#         try:\n",
    "#             tenured_un_tenured_total = np.sum([int(x['STAFF24']) for x in rows])\n",
    "#         except:\n",
    "#             tenured_un_tenured_total = np.sum([int(x['HRTOTLT']) for x in rows])\n",
    "            \n",
    "#         new_row[\"tenured_un_tenured_Grand_total\"] = tenured_un_tenured_total\n",
    "        \n",
    "        for rank in rank_object.keys():\n",
    "            if(rank ==\"rank_object\"):\n",
    "                continue\n",
    "            rows = [x for x in institution['faculty_demographics_year'][year] if rank_object[rank](x)]\n",
    "            for key, new_key in col_keys.items():\n",
    "                full_key = rank + \"_\" + new_key.replace(\" \",\"_\").replace(\"/\",\"_\")\n",
    "                if(len(rows)>0):\n",
    "                    if(key in rows[0].keys()):\n",
    "                        try:\n",
    "                            new_row[full_key] = int(rows[0][key])\n",
    "                        except:\n",
    "                            new_row[full_key] = None # empty column\n",
    "                    elif(full_key not in new_row.keys()):\n",
    "                        new_row[full_key] = None\n",
    "                else:\n",
    "                    new_row[full_key] = None\n",
    "        \n",
    "        tenured_un_tenured_grand_total = 0\n",
    "        if(new_row['non_tenured_Grand_total'] is not None):\n",
    "            tenured_un_tenured_grand_total += int(new_row['non_tenured_Grand_total'])\n",
    "        if(new_row['un_tenured_Grand_total'] is not None): \n",
    "            tenured_un_tenured_grand_total += int(new_row['un_tenured_Grand_total'])\n",
    "        if(new_row['tenured_Grand_total'] is not None): \n",
    "            tenured_un_tenured_grand_total += int(new_row['tenured_Grand_total'])\n",
    "            \n",
    "        new_row['tenured_un_tenured_Grand_total'] = tenured_un_tenured_grand_total\n",
    "        \n",
    "        all_rows.append(new_row)\n",
    "\n",
    "    print(\"Created {0} rows (years) for {1}\".format(len(all_rows), institution_name))\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#institutions['100654']['faculty_demographics_year']['2004-05']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch longitudinal data for all institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_institution_records = []\n",
    "included_institutions   = []\n",
    "\n",
    "for key, institution in institutions.items():\n",
    "    all_records = rows_for_institution(institution)\n",
    "    \n",
    "    if(len(all_records)>0):\n",
    "        all_institution_records += all_records\n",
    "        included_institutions.append({\"UNITID\":all_records[0]['UNITID'],\n",
    "                                      \"INSTNM\":all_records[0]['INSTNM'], \n",
    "                                      \"YEARS\": len(all_records)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List included institutions and how many rows were includedall_institution_records = []\n",
    "included_institutions   = []\n",
    "\n",
    "for key, institution in institutions.items():\n",
    "    all_records = rows_for_institution(institution)\n",
    "    \n",
    "    if(len(all_records)>0):\n",
    "        all_institution_records += all_records\n",
    "        included_institutions.append({\"UNITID\":all_records[0]['UNITID'],\n",
    "                                      \"INSTNM\":all_records[0]['INSTNM'], \n",
    "                                      \"YEARS\": len(all_records)})\n",
    "#included_institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Sums for institution Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated successfully\n"
     ]
    }
   ],
   "source": [
    "## if there are no errors, then the records add up\n",
    "for record in all_institution_records:\n",
    "    if(record['tenured_Grand_total_men'] is not None and\n",
    "       record['tenured_Grand_total_women'] is not None):\n",
    "        \n",
    "        assert record['tenured_Grand_total_men'] + record['tenured_Grand_total_women'] == record['tenured_Grand_total']\n",
    "\n",
    "        if(record['non_tenured_Grand_total'] is not None):\n",
    "            assert record['tenured_un_tenured_Grand_total'] == record['non_tenured_Grand_total'] + record['tenured_Grand_total'] \n",
    "            assert record['non_tenured_Grand_total_men'] + record['non_tenured_Grand_total_women'] == record['non_tenured_Grand_total']\n",
    "        elif(record['un_tenured_Grand_total'] is not None): \n",
    "            assert record['tenured_un_tenured_Grand_total'] == record['un_tenured_Grand_total'] + record['tenured_Grand_total'] \n",
    "            assert record['un_tenured_Grand_total_men'] + record['un_tenured_Grand_total_women'] == record['un_tenured_Grand_total']\n",
    "\n",
    "print(\"Validated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Merge Carnegie Categories\n",
    "\n",
    "* [Documentation on Carnegie Classification](https://carnegieclassifications.iu.edu/classification_descriptions/basic.php) \n",
    "* Column explanations and data codes are available in the data_path folder in `CCIHE2018-PublicData.xlsx`\n",
    "\n",
    "#### Meaning of the BASIC2018 codes:\n",
    "* 1\tAssociate's Colleges: High Transfer-High Traditional\n",
    "* 2\tAssociate's Colleges: High Transfer-Mixed Traditional/Nontraditional\n",
    "* 3\tAssociate's Colleges: High Transfer-High Nontraditional\n",
    "* 4\tAssociate's Colleges: Mixed Transfer/Career & Technical-High Traditional\n",
    "* 5\tAssociate's Colleges: Mixed Transfer/Career & Technical-Mixed Traditional/Nontraditional\n",
    "* 6\tAssociate's Colleges: Mixed Transfer/Career & Technical-High Nontraditional\n",
    "* 7\tAssociate's Colleges: High Career & Technical-High Traditional\n",
    "* 8\tAssociate's Colleges: High Career & Technical-Mixed Traditional/Nontraditional\n",
    "* 9\tAssociate's Colleges: High Career & Technical-High Nontraditional\n",
    "* 10\tSpecial Focus Two-Year: Health Professions\n",
    "* 11\tSpecial Focus Two-Year: Technical Professions\n",
    "* 12\tSpecial Focus Two-Year: Arts & Design\n",
    "* 13\tSpecial Focus Two-Year: Other Fields\n",
    "* 14\tBaccalaureate/Associate's Colleges: Associate's Dominant\n",
    "* 15\tDoctoral Universities: Very High Research Activity\n",
    "* 16\tDoctoral Universities: High Research Activity\n",
    "* 17\tDoctoral/Professional Universities\n",
    "* 18\tMaster's Colleges & Universities: Larger Programs\n",
    "* 19\tMaster's Colleges & Universities: Medium Programs\n",
    "* 20\tMaster's Colleges & Universities: Small Programs\n",
    "* 21\tBaccalaureate Colleges: Arts & Sciences Focus\n",
    "* 22\tBaccalaureate Colleges: Diverse Fields\n",
    "* 23\tBaccalaureate/Associate's Colleges: Mixed Baccalaureate/Associate's\n",
    "* 24\tSpecial Focus Four-Year: Faith-Related Institutions\n",
    "* 25\tSpecial Focus Four-Year: Medical Schools & Centers\n",
    "* 26\tSpecial Focus Four-Year: Other Health Professions Schools\n",
    "* 27\tSpecial Focus Four-Year: Engineering Schools\n",
    "* 28\tSpecial Focus Four-Year: Other Technology-Related Schools\n",
    "* 29\tSpecial Focus Four-Year: Business & Management Schools\n",
    "* 30\tSpecial Focus Four-Year: Arts, Music & *  Schools\n",
    "* 31\tSpecial Focus Four-Year: Law Schools\n",
    "* 32\tSpecial Focus Four-Year: Other Special Focus Institutions\n",
    "* 33\tTribal Colleges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/IPEDS_DATA_FOLDER/CCIHE2018-PublicData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m important_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNITID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# IPEDS ID\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHBCU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#historically black college/university\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBASIC2018\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      9\u001b[0m carnegie_categories \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mopen(data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCCIHE2018-PublicData.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csv\u001b[38;5;241m.\u001b[39mDictReader(f):\n\u001b[0;32m     12\u001b[0m         new_row \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m<frozen codecs>:906\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/IPEDS_DATA_FOLDER/CCIHE2018-PublicData.csv'"
     ]
    }
   ],
   "source": [
    "important_columns = [\n",
    "    \"UNITID\", # IPEDS ID\n",
    "    \"HBCU\", #historically black college/university\n",
    "    \"HSI \",  #hispanic-serving institution\n",
    "    \"TRIBAL\",\n",
    "    \"BASIC2018\"\n",
    "]\n",
    "\n",
    "carnegie_categories = {}\n",
    "with codecs.open(data_path + \"CCIHE2018-PublicData.csv\", encoding='utf-8-sig') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        new_row = {}\n",
    "        for col in important_columns:\n",
    "            #strip the new col since HSI has an extra space in the Carnegie data\n",
    "            #and I don't want to pass on the missing space\n",
    "            new_row[col.strip()] = row[col] \n",
    "        carnegie_categories[row['UNITID']] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge In Carnegie Categories by Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in all_institution_records:\n",
    "    unitid = record['UNITID']\n",
    "    if unitid in carnegie_categories.keys():\n",
    "        carnegie_row = carnegie_categories[unitid]\n",
    "    else:\n",
    "        carnegie_row = {\"BASIC2018\": None, \"HBCU\":None, \"HSI\":None, \"TRIBAL\":None}\n",
    "    for col in carnegie_row.keys():\n",
    "        record[col] = carnegie_row[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([x['BASIC2018'] for x in all_institution_records])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic: print out unique institutions that don't have a Carnegie classification in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set([x['INSTNM'] for x in all_institution_records if x['BASIC2018']  is None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Merge Opportunity Insights Categories\n",
    "\n",
    "* mrc_table10.csv: [College Level Characteristics from the Opportunity Insights College Scorecard](https://opportunityinsights.org/wp-content/uploads/2018/04/Codebook-MRC-Table-10.pdf)\n",
    "* [Opportunity insights data page](https://opportunityinsights.org/data/?geographic_level=0&topic=0&paper_id=536#resource-listing)\n",
    "\n",
    "Note: I wrote \n",
    "\n",
    "Columns:\n",
    "* **super_opeid**: Institution  OPEID  /    Cluster  ID  when  combining  multiple OPEIDs\n",
    "* **name**: Name of Institution / Super-OPEID Cluster\n",
    "* **tier**: Selectivity and type combination (constructed from other columns in the dataset):\n",
    "  * 1 = Ivy Plus (**this is effectively the only category we can merge, due to [the problem of super-OPEIDS](https://robertkelchen.com/2017/08/21/beware-opeids-and-super-opeids/)**)\n",
    "  * 2 = Other elite schools (public and private)\n",
    "  * 3 = Highly selective public\n",
    "  * 4 = Highly selective private\n",
    "  * 5 = Selective public\n",
    "  * 6 = Selective private\n",
    "  * 7 = Nonselective 4-year public\n",
    "  * 8 = Nonselective 4-year private not-for-profit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/IPEDS_DATA_FOLDER/mrc_table10.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m important_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuper_opeid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# Super OPEID\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#name\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtier_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#tier name\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtier\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# the categories of interest\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ]\n\u001b[0;32m      8\u001b[0m op_insights \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mopen(data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrc_table10.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csv\u001b[38;5;241m.\u001b[39mDictReader(f):\n\u001b[0;32m     11\u001b[0m         new_row \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m<frozen codecs>:906\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/IPEDS_DATA_FOLDER/mrc_table10.csv'"
     ]
    }
   ],
   "source": [
    "important_columns = [\n",
    "    \"super_opeid\", # Super OPEID\n",
    "    \"name\", #name\n",
    "    \"tier_name\", #tier name\n",
    "    \"tier\" # the categories of interest\n",
    "]\n",
    "\n",
    "op_insights = {}\n",
    "with codecs.open(data_path + \"mrc_table10.csv\", encoding='utf-8-sig') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        new_row = {}\n",
    "        for col in important_columns:\n",
    "            new_row[col] = row[col]\n",
    "        op_insights[row['super_opeid']] = new_row\n",
    "print(\"{0} opportunity insights categories loaded\".format(len(op_insights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge IvyPlus\n",
    "This is the one Opportunity Insights category we can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IvyPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m tier_code \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m op_insights_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m op_insights\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtier\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtier_code])\n\u001b[1;32m----> 4\u001b[0m tier_name \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtier_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m op_insights\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtier\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtier_code][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m total \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(op_insights_group), tier_name))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m op_insights_group:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## CONFIRM THAT IVYPLUS CAN BE MERGED\n",
    "tier_code ='1'\n",
    "op_insights_group = set([x['name'].strip().lower() for x in op_insights.values() if x['tier']==tier_code])\n",
    "tier_name = [x['tier_name'] for x in op_insights.values() if x['tier']==tier_code][0].lower().replace(\" \",\".\")\n",
    "\n",
    "print(\"{0} total {1}\\n\".format(len(op_insights_group), tier_name))\n",
    "\n",
    "for name in op_insights_group:\n",
    "    found = False\n",
    "    for institution in institutions.values():\n",
    "        if(institution['INSTNM'].strip().lower() == name):\n",
    "            found = True\n",
    "    print(\"{0} {1}\".format(found, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tier_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m         row[tier_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m merged\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(op_insights_merged), tier_name))\n\u001b[0;32m     11\u001b[0m op_insights_merged\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tier_name' is not defined"
     ]
    }
   ],
   "source": [
    "## MERGE IVYPLUS\n",
    "op_insights_merged = set()\n",
    "for row in all_institution_records:\n",
    "    if row['INSTNM'].strip().lower() in op_insights_group:\n",
    "        row[tier_name] = 1\n",
    "        op_insights_merged.add(row['INSTNM'])\n",
    "    else:\n",
    "        row[tier_name] = 0\n",
    "        pass\n",
    "print(\"{0} {1} merged\".format(len(op_insights_merged), tier_name))\n",
    "op_insights_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add US News and World Reports Categories\n",
    "Documentation is available on the [Best Colleges Ranking Category Definition](https://www.usnews.com/education/best-colleges/articles/ranking-category-definitions) guide (last updated Sept 13, 2020. Accessed August 9, 2021). They are essentially supersets of Carnegie Categories.\n",
    "\n",
    "Region divisions are taken from the [official US Census regions](https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf), and are stored in this repository in `data/us-census-regions.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows (not institutions) with each category:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## See the key under \" Load and Merge Carnegie Categories\" \n",
    "# for the relationship between BASIC2018 codes \n",
    "#  and human-readable Carnegie Categories\n",
    "\n",
    "usnews_categories ={\n",
    "    \"15\": \"National Universities\",\n",
    "    \"16\": \"National Universities\",\n",
    "    \"18\": \"Regional Universities\",\n",
    "    \"19\": \"Regional Universities\",\n",
    "    \"20\": \"Regional Universities\",\n",
    "    \"21\": \"National Liberal Arts Colleges\",\n",
    "    \"22\": \"Regional Colleges\",\n",
    "    \"23\": \"Regional Colleges\",\n",
    "    \"14\": \"Regional Colleges\",\n",
    "    \"24\": \"Special Focus Four-Year: Faith-Related Institutions\",\n",
    "    \"25\": \"Special Focus Four-Year: Medical Schools & Centers\",\n",
    "    \"26\": \"Special Focus Four-Year: Other Health Professions Schools\",\n",
    "    \"27\": \"Special Focus Four-Year: Engineering Schools\",\n",
    "    \"28\": \"Special Focus Four-Year: Other Technology-Related Schools\",\n",
    "    \"29\": \"Special Focus Four-Year: Business & Management Schools\",\n",
    "    \"30\": \"Special Focus Four-Year: Arts, Music & * Schools\",\n",
    "    \"31\": \"Special Focus Four-Year: Law Schools\",\n",
    "    \"32\": \"Special Focus Four-Year: Other Special Focus Institutions\"\n",
    "}\n",
    "\n",
    "for row in all_institution_records:\n",
    "    if row['BASIC2018'] in usnews_categories:\n",
    "        row['usnews_category']  = usnews_categories[row['BASIC2018']]\n",
    "    else:\n",
    "        row['usnews_category']  = None\n",
    "        \n",
    "print(\"Rows (not institutions) with each category:\")\n",
    "Counter([x['usnews_category'] for x in all_institution_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/us-census-regions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Load Census Regions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m state_region \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/us-census-regions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csv\u001b[38;5;241m.\u001b[39mDictReader(f):\n\u001b[0;32m      5\u001b[0m         state_region[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState Code\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/us-census-regions.csv'"
     ]
    }
   ],
   "source": [
    "## Load Census Regions\n",
    "state_region = {}\n",
    "with open(\"data/us-census-regions.csv\") as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        state_region[row['State Code']] = row['Region']\n",
    "        \n",
    "        \n",
    "## add a few regions to follow the US News and World Report\n",
    "state_region['PR'] = \"South\"\n",
    "state_region['MP'] = \"West\"\n",
    "state_region['VI'] = \"South\"\n",
    "state_region['GU'] = \"West\"\n",
    "state_region['AS'] = \"West\"\n",
    "\n",
    "## Apply Census Regions to Regional Institutions, following the US News System \n",
    "for row in all_institution_records:\n",
    "    if (row['usnews_category'] in ['Regional Universities', \"Regional Colleges\"]):\n",
    "        if(row['STABBR'] in state_region.keys()):\n",
    "            row['usnews_category'] += \"â\" + state_region[row['STABBR']]\n",
    "        else:\n",
    "            row['usnews_category'] += \"â\" + row['STABBR']\n",
    "        \n",
    "print(\"Rows (not institutions) with each category:\")\n",
    "Counter([x['usnews_category'] for x in all_institution_records])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Column for HSI/HBCU/Tribal and IVYPLUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in all_institution_records:\n",
    "    record['hsi_hbcu_tribal'] = record['HSI'] or record['HBCU'] or record['TRIBAL']\n",
    "    record['ivy_plus'] = record['ivy.plus']  ==1\n",
    "\n",
    "# for record in all_institution_records:\n",
    "#     if record['UNITID'] in institution_pwi.keys():\n",
    "#         record['pwi'] = institution_pwi[record['UNITID']]>50\n",
    "#         record['pct_white_2019'] = institution_pwi[record['UNITID']]\n",
    "#     else:\n",
    "#         record['pwi'] = None\n",
    "#         record['pct_white_2019'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Percentages for Every Level\n",
    "This code computes percentages for every group and subgroup in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = ['tenured_full', 'tenured_associate', 'un_tenured_assistant']\n",
    "\n",
    "## our analysis is only focused on subroups from 2012 onward\n",
    "## so we only include the demographic characteristics after that time\n",
    "demo_groups = ['American Indian or Alaska Native',\n",
    "               'Asian',\n",
    "               'Black or African American',\n",
    "               'Hispanic or Latino',\n",
    "               'Native Hawaiian or Other Pacific Islander',\n",
    "               'Nonresident alien',\n",
    "               'Race/ethnicity unknown',\n",
    "               'Two or more races',\n",
    "               'White']\n",
    "\n",
    "## we define the following demographic groups\n",
    "## as \"URM\" for this analysis\n",
    "urm_demo_groups = ['American Indian or Alaska Native',\n",
    "                   'Black or African American',\n",
    "                   'Hispanic or Latino',\n",
    "                   'Native Hawaiian or Other Pacific Islander',\n",
    "                   'Two or more races']\n",
    "urm_demo_key    = \"black_latino_american_indian_alaska_native_hawaiian_pacific_multiracial\"\n",
    "\n",
    "gender_groups = ['men', 'women']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#institution_row = [x for x in all_institution_records if x['INSTNM'].find(\"ornell\")>-1 and x['year']=='2019-20'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL SUB-GROUPS ARE RECORDED\n",
    "## AS A PERCENTAGE OF THE RANK\n",
    "\n",
    "def set_pct_demo_values(institution_row):\n",
    "    rank_totals = defaultdict(int)\n",
    "    \n",
    "    for rank in ranks:\n",
    "        rank_key = rank + \"_\" + \"Grand_total\"\n",
    "    #     print(\"{0}: {1}: {2}\".format(\n",
    "    #         rank_key in institution_row.keys(),\n",
    "    #         institution_row[rank_key],\n",
    "    #         rank_key))\n",
    "    \n",
    "        rank_totals[rank] = 0\n",
    "\n",
    "        # for each recorded gender\n",
    "        for gender in gender_groups:\n",
    "            rank_gender_key = rank_key + \"_\" + gender\n",
    "\n",
    "            if(institution_row[rank_gender_key] is not None):\n",
    "                pct = (float(institution_row[rank_gender_key]) / institution_row[rank_key])*100.\n",
    "            else:\n",
    "                pct = None        \n",
    "\n",
    "            # convention for gender key: replace _Grand_total and add _pct at the end\n",
    "            institution_row[rank_gender_key.replace(\"_Grand_total\", \"\") + \"_pct\"] = pct\n",
    "\n",
    "    #         print(\"{0}: {1}: {2}, {3}\".format(\n",
    "    #             rank_gender_key in institution_row.keys(),\n",
    "    #             institution_row[rank_gender_key],\n",
    "    #             rank_gender_key,\n",
    "    #             rank_gender_key.replace(\"_Grand_total\", \"\") + \"_pct\"))\n",
    "    #         print(\"    {0}\".format(pct))        \n",
    "    \n",
    "        # for each demographic group\n",
    "        for demo in demo_groups:\n",
    "            demo_key = rank + \"_\" + demo.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total\"\n",
    "            \n",
    "            if(institution_row[demo_key] is not None):\n",
    "                pct = (float(institution_row[demo_key]) / institution_row[rank_key])*100.\n",
    "                \n",
    "                if(demo in urm_demo_groups):\n",
    "                    rank_totals[rank] += institution_row[demo_key]\n",
    "                \n",
    "            else:\n",
    "                pct = None\n",
    "\n",
    "            # convention for demo key: replace \"_total\" with \"_pct\"\n",
    "            institution_row[demo_key.replace(\"_total\", \"_pct\")] = pct\n",
    "\n",
    "    #         print(\"{0}: {1}: {2}\".format(\n",
    "    #             demo_key in institution_row.keys(),\n",
    "    #             institution_row[demo_key],\n",
    "    #             demo_key))\n",
    "    #         print(\"    {0}\".format(pct))\n",
    "\n",
    "            # for each gender within demographic groups\n",
    "            for gender in gender_groups:\n",
    "                demo_gender_key = rank + \"_\" + demo.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_\" + gender      \n",
    "\n",
    "                if(institution_row[demo_gender_key] is not None and \n",
    "                   institution_row[rank_key] is not None and\n",
    "                   institution_row[rank_key] != 0):\n",
    "                    pct = (float(institution_row[demo_gender_key]) / float(institution_row[rank_key]) * 100.)\n",
    "                else:\n",
    "                    pct = None\n",
    "\n",
    "                #convention for demo_gender_key: add _pct at end\n",
    "\n",
    "                institution_row[demo_gender_key+\"_pct\"] = pct\n",
    "    #             print(\"{0}: {1}: {2}\".format(\n",
    "    #                 demo_gender_key in institution_row.keys(),\n",
    "    #                 institution_row[demo_gender_key],\n",
    "    #                 demo_gender_key))\n",
    "    #             print(\"    {0}\".format(pct))\n",
    "    \n",
    "    ## add rank totals\n",
    "    all_rank_total = 0\n",
    "    for rank in ranks:\n",
    "        institution_row[rank + \"_\" + urm_demo_key + \"_total\"] = rank_totals[rank]\n",
    "        all_rank_total += rank_totals[rank]\n",
    "    institution_row[\"tenured_un_tenured_\" + urm_demo_key + \"_total\"] = all_rank_total\n",
    "    institution_row[\"tenured_un_tenured_\" + urm_demo_key + \"_pct\"] = all_rank_total / row['tenured_un_tenured_Grand_total'] if row['tenured_un_tenured_Grand_total'] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set demographic values for each institution\n",
    "for row in all_institution_records:\n",
    "    set_pct_demo_values(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation successful\n"
     ]
    }
   ],
   "source": [
    "for record in all_institution_records:\n",
    "    for rank in ranks:\n",
    "        rank_key = rank + \"_\" + \"Grand_total\"\n",
    "        calc_total = 0\n",
    "        for gender in gender_groups:\n",
    "            rank_gender_key = rank_key + \"_\" + gender\n",
    "            if record[rank_gender_key] is not None:\n",
    "                calc_total += record[rank_gender_key]\n",
    "        stored_total = 0\n",
    "        if(record[rank_key] is not None):\n",
    "            stored_total = record[rank_key]\n",
    "        \n",
    "        ## if this runs successfully for every row without an assertion error, then the grand total\n",
    "        ## is equal to the totals for men and women for every rank.\n",
    "        assert calc_total == stored_total\n",
    "print(\"Validation successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:\\Users\\jnajab.AD\\IPEDS_DATA_FOLDER'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_institution_records)\u001b[38;5;241m.\u001b[39mto_csv(data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_all_institution_records.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      2\u001b[0m                                              index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3903\u001b[0m     path_or_buf,\n\u001b[0;32m   3904\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3905\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3906\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3907\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3908\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3909\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3910\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3911\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3912\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3913\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3914\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3915\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3916\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3917\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3918\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3919\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    251\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    252\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    253\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 739\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'C:\\Users\\jnajab.AD\\IPEDS_DATA_FOLDER'"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(all_institution_records).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \"_all_institution_records.csv\",\n",
    "                                             index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Tables for Reporting and Visualization\n",
    "\n",
    "## Identify Institutions / Rows To Include and Exclude\n",
    "\n",
    "* Exclude years before 2012-2013\n",
    "\n",
    "* Institutions that no longer exist or are no longer reporting are omitted from the dataset.\n",
    "\n",
    "* Institutions reporting two years or fewer are omitted from the dataset.\n",
    "\n",
    "* Institutions that don't appear in the US News and World Reports classification clusters are omitted.\n",
    "\n",
    "* Institutions that don't report how many tenured or un-tenured faculty they had in 2019 are omitted from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m all_institution_records:\n\u001b[0;32m      2\u001b[0m     record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_int\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m all_institution_records[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_int\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for record in all_institution_records:\n",
    "    record['year_int']  = int(record['year'][0:4])\n",
    "\n",
    "all_institution_records[0]['year_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 0 records out of 0\n",
      "Omitting 0 records out of 0\n",
      "Omitting 0 institutions for having no record of full/associate/assistant totals.\n"
     ]
    }
   ],
   "source": [
    "## include only records since 2012\n",
    "institution_records = [x for x in all_institution_records if x['year_int']>=2012]\n",
    "print(\"Keeping {0} records out of {1}\".format(len(institution_records), len(all_institution_records)))\n",
    "\n",
    "\n",
    "## include only institutions that reported at least three years\n",
    "institution_counts = Counter([x['UNITID'] for x in institution_records])\n",
    "insufficient_records =  {k: v for k, v in institution_counts.items() if v <= 2}\n",
    "print(\"Omitting {0} records out of {1}\".format(len(insufficient_records), len(institution_records)))\n",
    "\n",
    "#['tenured_full', 'tenured_associate', 'un_tenured_assistant']\n",
    "\n",
    "## omit institutions that have no recorded data for full, associate, or assistant\n",
    "no_tenure_records = set([x['UNITID'] for x in institution_records if x['year_int']==2019 and \n",
    "                     (x['tenured_full_Grand_total'] is None or\n",
    "                      x['tenured_associate_Grand_total'] is None or\n",
    "                      x['un_tenured_assistant_Grand_total'] is None)])\n",
    "\n",
    "print(\"Omitting {0} institutions for having no record of full/associate/assistant totals.\".format(len(no_tenure_records)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included institutions: 1250 out of 4852\n"
     ]
    }
   ],
   "source": [
    "institutions_to_include = [\n",
    "    x['UNITID'] for x in institution_records if\n",
    "    x['year_int']  == 2019 and           # exists in 2019\n",
    "    x['usnews_category'] is not None and # has a US News category\n",
    "    x['UNITID'] not in insufficient_records.keys() and\n",
    "    x['UNITID'] not in no_tenure_records\n",
    "]\n",
    "print(\"Included institutions: {0} out of {1}\".format(len(institutions_to_include), \n",
    "                                                     len(set([x['UNITID'] for x in institution_records]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_years = [x for x in institution_records if x['UNITID']  in institutions_to_include]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Timeseries Tables\n",
    "\n",
    "Tables need:\n",
    "* Counts for each category (done)\n",
    "* Percentages for each category\n",
    "* Estimate, upper/lower confidence interval for a linear regression for percentages in each category, with the specification:\n",
    "  * $Y = \\beta_0 + \\beta_11 \\times YEAR + \\epsilon$\n",
    "\n",
    "Summary tables:\n",
    "* HBCU + HSI + Tribal compared to the rest\n",
    "* Per-category\n",
    "\n",
    "Non-summary tables:\n",
    "* Per-institution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HBCU + HSI + Tribal compared to the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE DATASTRUCTURE FOR WHICH KEYS TO DIVIDE BY WHICH\n",
    "\n",
    "# each column key is the numerator\n",
    "# with each value the denominator for that key\n",
    "split_table_cols = {}\n",
    "\n",
    "for rank in ranks:\n",
    "    rank_total_key = rank + \"_\" + \"Grand_total\"\n",
    "    split_table_cols[rank_total_key] = rank_total_key\n",
    "\n",
    "    for gender in gender_groups:\n",
    "        rank_gender_total_key = rank_total_key + \"_\" + gender\n",
    "        #rank_gender_pct_key = rank_gender_total_key.replace(\"_Grand_total\", \"\") + \"_pct\"\n",
    "        split_table_cols[rank_gender_total_key] = rank_total_key\n",
    "\n",
    "    for demo in demo_groups:\n",
    "        demo_total_key = rank + \"_\" + demo.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total\"\n",
    "        #demo_pct_key = demo_total_key.replace(\"_total\", \"_pct\")\n",
    "        split_table_cols[demo_total_key] = rank_total_key\n",
    "\n",
    "        for gender in gender_groups:\n",
    "            demo_gender_total_key = rank + \"_\" + demo.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_\" + gender      \n",
    "            #demo_gender_pct_key = demo_gender_total_key + \"_pct\"\n",
    "            split_table_cols[demo_gender_total_key] = rank_total_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tenured_associate_Grand_total',\n",
       " 'tenured_full_Grand_total',\n",
       " 'un_tenured_assistant_Grand_total'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x for x in split_table_cols.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tenured_full_Grand_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Grand_total_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Grand_total_women': 'tenured_full_Grand_total',\n",
       " 'tenured_full_American_Indian_or_Alaska_Native_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_American_Indian_or_Alaska_Native_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_American_Indian_or_Alaska_Native_women': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Asian_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Asian_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Asian_women': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Black_or_African_American_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Black_or_African_American_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Black_or_African_American_women': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Hispanic_or_Latino_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Hispanic_or_Latino_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Hispanic_or_Latino_women': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Native_Hawaiian_or_Other_Pacific_Islander_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Native_Hawaiian_or_Other_Pacific_Islander_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Native_Hawaiian_or_Other_Pacific_Islander_women': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Nonresident_alien_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Nonresident_alien_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Nonresident_alien_women': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Race_ethnicity_unknown_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Race_ethnicity_unknown_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Race_ethnicity_unknown_women': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Two_or_more_races_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Two_or_more_races_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_Two_or_more_races_women': 'tenured_full_Grand_total',\n",
       " 'tenured_full_White_total': 'tenured_full_Grand_total',\n",
       " 'tenured_full_White_men': 'tenured_full_Grand_total',\n",
       " 'tenured_full_White_women': 'tenured_full_Grand_total',\n",
       " 'tenured_associate_Grand_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Grand_total_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Grand_total_women': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_American_Indian_or_Alaska_Native_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_American_Indian_or_Alaska_Native_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_American_Indian_or_Alaska_Native_women': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Asian_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Asian_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Asian_women': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Black_or_African_American_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Black_or_African_American_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Black_or_African_American_women': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Hispanic_or_Latino_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Hispanic_or_Latino_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Hispanic_or_Latino_women': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Native_Hawaiian_or_Other_Pacific_Islander_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Native_Hawaiian_or_Other_Pacific_Islander_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Native_Hawaiian_or_Other_Pacific_Islander_women': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Nonresident_alien_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Nonresident_alien_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Nonresident_alien_women': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Race_ethnicity_unknown_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Race_ethnicity_unknown_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Race_ethnicity_unknown_women': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Two_or_more_races_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Two_or_more_races_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_Two_or_more_races_women': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_White_total': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_White_men': 'tenured_associate_Grand_total',\n",
       " 'tenured_associate_White_women': 'tenured_associate_Grand_total',\n",
       " 'un_tenured_assistant_Grand_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Grand_total_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Grand_total_women': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_American_Indian_or_Alaska_Native_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_American_Indian_or_Alaska_Native_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_American_Indian_or_Alaska_Native_women': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Asian_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Asian_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Asian_women': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Black_or_African_American_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Black_or_African_American_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Black_or_African_American_women': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Hispanic_or_Latino_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Hispanic_or_Latino_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Hispanic_or_Latino_women': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Native_Hawaiian_or_Other_Pacific_Islander_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Native_Hawaiian_or_Other_Pacific_Islander_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Native_Hawaiian_or_Other_Pacific_Islander_women': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Nonresident_alien_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Nonresident_alien_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Nonresident_alien_women': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Race_ethnicity_unknown_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Race_ethnicity_unknown_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Race_ethnicity_unknown_women': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Two_or_more_races_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Two_or_more_races_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_Two_or_more_races_women': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_White_total': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_White_men': 'un_tenured_assistant_Grand_total',\n",
       " 'un_tenured_assistant_White_women': 'un_tenured_assistant_Grand_total'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_table_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_row():\n",
    "    return defaultdict(int)\n",
    "\n",
    "## exclude from split tables any subgroups where the denominator\n",
    "## of faculty for a given rank is 0. That would mean that no institutions\n",
    "## reported any faculty in that rank that year\n",
    "\n",
    "def return_split_table(record_years, split_table_key):        \n",
    "    included_years = set([x['year_int'] for x in record_years])\n",
    "\n",
    "    subgroup_table_rows = []\n",
    "\n",
    "    for subgroup_key in set([x[split_table_key] for x in record_years]):\n",
    "        row = defaultdict(year_row)        \n",
    "\n",
    "        subgroup_institution_years = [x for x in record_years if x[split_table_key] == subgroup_key]\n",
    "\n",
    "        unique_denominator_keys = set([x for x in split_table_cols.values()])\n",
    "\n",
    "        for institution_year in subgroup_institution_years:\n",
    "            \n",
    "            ## TODO: for some reason, this code is double-counting denominators. FIx.\n",
    "            for denominator_key in unique_denominator_keys:\n",
    "                if(institution_year[denominator_key] is not None):\n",
    "                    row[institution_year['year_int']][denominator_key+\"_sum\"] += institution_year[denominator_key]\n",
    "\n",
    "            for numerator_key, denominator_key in split_table_cols.items():\n",
    "                ## only add the numerator if the denominator is not None (likely rare)\n",
    "                if(institution_year[numerator_key] is not None and institution_year[denominator_key] is not None):\n",
    "                    row[institution_year['year_int']][numerator_key + \"_sum\"] += institution_year[numerator_key]\n",
    "                elif(institution_year[denominator_key] is None and institution_year[numerator_key] is not None):\n",
    "                    print(\"denominator key None but numerator exists!!!\")\n",
    "\n",
    "        # patch the tenured and un-tenured sums. TODO: fix the code block starting at line 22\n",
    "        for year in included_years:\n",
    "            row[year]['tenured_full_Grand_total_sum'] = row[year]['tenured_full_Grand_total_women_sum'] + row[year]['tenured_full_Grand_total_men_sum']\n",
    "            row[year]['tenured_associate_Grand_total_sum'] = row[year]['tenured_associate_Grand_total_women_sum'] + row[year]['tenured_associate_Grand_total_men_sum']\n",
    "            row[year]['un_tenured_assistant_Grand_total_sum'] = row[year]['un_tenured_assistant_Grand_total_women_sum'] + row[year]['un_tenured_assistant_Grand_total_men_sum']\n",
    "            row[year]['tenured_un_tenured_Grand_total_sum'] = row[year]['tenured_full_Grand_total_sum'] + row[year]['tenured_associate_Grand_total_sum'] + row[year]['un_tenured_assistant_Grand_total_sum']\n",
    "            \n",
    "            ## add in joint tenured and un_tenured totals\n",
    "            ## and joint tenured and un_tenured totals for URM\n",
    "            total_tt_urm_key = \"tenured_un_tenured_\" + urm_demo_key + \"_total_sum\"\n",
    "            row[year][total_tt_urm_key]  = 0\n",
    "            for group in urm_demo_groups:\n",
    "                tf_key  = \"tenured_full_\" + group.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total_sum\"\n",
    "                ta_key  = \"tenured_associate_\" + group.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total_sum\"\n",
    "                ut_key  = \"un_tenured_assistant_\" + group.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total_sum\"\n",
    "                \n",
    "                row[year][total_tt_urm_key] += row[year][tf_key]\n",
    "                row[year][total_tt_urm_key] += row[year][ta_key]\n",
    "                row[year][total_tt_urm_key] += row[year][ut_key]\n",
    "            \n",
    "            ## now add pct URM tenure track faculty\n",
    "            if(row[year]['tenured_un_tenured_Grand_total_sum']):\n",
    "                row[year][\"tenured_un_tenured_\" + urm_demo_key + \"_total_pct\"] = \\\n",
    "                    float(row[year][total_tt_urm_key]) / float(row[year]['tenured_un_tenured_Grand_total_sum']) \n",
    "            else:\n",
    "                row[year][\"tenured_un_tenured_\" + urm_demo_key + \"_total_pct\"] = None\n",
    "                    \n",
    "        \n",
    "        for year in included_years:\n",
    "            \n",
    "            zero_denominator = False\n",
    "            \n",
    "            for numerator_key, denominator_key in split_table_cols.items():\n",
    "                try:\n",
    "                    row[year][numerator_key + \"_pct\"] = (row[year][numerator_key + \"_sum\"] / row[year][denominator_key + \"_sum\"])*100.\n",
    "                except ZeroDivisionError:\n",
    "                    row[year][numerator_key + \"_pct\"] = None\n",
    "                    zero_denominator = True\n",
    "\n",
    "                    \n",
    "            row[year]['year'] = year\n",
    "            row[year][\"subgroup\"]  = split_table_key\n",
    "            row[year][\"subgroup_value\"] = subgroup_key\n",
    "            \n",
    "            row[year]['num_institutions'] = len(set([x['UNITID'] for x in subgroup_institution_years if x['year_int'] == year]))\n",
    "                     \n",
    "            # skip if there's a zero denominator\n",
    "            if(zero_denominator):\n",
    "                print(\"Zero denominator: {0}, {1}, {2}\".format(year, split_table_key, subgroup_key))\n",
    "            else:\n",
    "                subgroup_table_rows.append(row[year])\n",
    "    return subgroup_table_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_urm_faculty_columns(split_table_row):\n",
    "    urm_total = 0\n",
    "    total_tt_urm_key = \"tenured_un_tenured_\" + urm_demo_key + \"_total_sum\"\n",
    "    \n",
    "    for group in urm_demo_groups:\n",
    "        tf_key  = \"tenured_full_\" + group.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total_sum\"\n",
    "        ta_key  = \"tenured_associate_\" + group.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total_sum\"\n",
    "        ut_key  = \"un_tenured_assistant_\" + group.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total_sum\"\n",
    "        urm_total += split_table_row[tf_key]\n",
    "        urm_total += split_table_row[ta_key]\n",
    "        urm_total += split_table_row[ut_key]\n",
    "\n",
    "    assert urm_total == split_table_row[total_tt_urm_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False, True}\n"
     ]
    }
   ],
   "source": [
    "## confirm that there are only two values\n",
    "print(set([x['ivy_plus'] for x in institution_years]))\n",
    "\n",
    "## generate split table, one row for every year\n",
    "ivy_plus_table = return_split_table(institution_years, 'ivy_plus')\n",
    "\n",
    "## validate totals\n",
    "[validate_urm_faculty_columns(x) for x in ivy_plus_table]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_urm_faculty_columns(ivy_plus_table[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0', '1'}\n"
     ]
    }
   ],
   "source": [
    "## confirm that there are only two values\n",
    "print(set([x['hsi_hbcu_tribal'] for x in institution_years]))\n",
    "\n",
    "## generate split table, one row for every year\n",
    "hsi_hbcu_tribal_table = return_split_table(institution_years, 'hsi_hbcu_tribal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Special Focus Four-Year: Medical Schools & Centers', 'Regional UniversitiesâWest', 'Special Focus Four-Year: Engineering Schools', 'Regional CollegesâMidwest', 'Special Focus Four-Year: Faith-Related Institutions', 'Regional CollegesâSouth', 'Special Focus Four-Year: Business & Management Schools', 'Special Focus Four-Year: Arts, Music & * Schools', 'Regional CollegesâNortheast', 'Regional CollegesâWest', 'Special Focus Four-Year: Other Health Professions Schools', 'Regional UniversitiesâNortheast', 'Regional UniversitiesâMidwest', 'Special Focus Four-Year: Other Special Focus Institutions', 'Special Focus Four-Year: Other Technology-Related Schools', 'Special Focus Four-Year: Law Schools', 'National Liberal Arts Colleges', 'Regional UniversitiesâSouth', 'National Universities'}\n",
      "Zero denominator: 2012, usnews_category, Special Focus Four-Year: Business & Management Schools\n",
      "Zero denominator: 2012, usnews_category, Special Focus Four-Year: Other Technology-Related Schools\n",
      "Zero denominator: 2014, usnews_category, Special Focus Four-Year: Other Technology-Related Schools\n"
     ]
    }
   ],
   "source": [
    "## confirm values\n",
    "print(set([x['usnews_category'] for x in institution_years]))\n",
    "\n",
    "## generate split table, one row for every year\n",
    "usnews_category_table = return_split_table(institution_years, 'usnews_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#institution_years[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'30', '24', '23', '22', '19', '18', '31', '26', '20', '14', '32', '28', '21', '16', '15', '25', '27', '29'}\n",
      "Zero denominator: 2012, BASIC2018, 28\n",
      "Zero denominator: 2014, BASIC2018, 28\n",
      "Zero denominator: 2012, BASIC2018, 29\n"
     ]
    }
   ],
   "source": [
    "## confirm values for carnegie categories\n",
    "print(set([x['BASIC2018'] for x in institution_years]))\n",
    "carnegie_category_table = return_split_table(institution_years, 'BASIC2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Linear Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## the code accepts a custom year key so it can be used\n",
    "## on the summary tables for collections of institutions\n",
    "## as well as records for individual institutions\n",
    "def generate_regression_table(institution_table, year_key = 'year'):\n",
    "    result_rows = []\n",
    "\n",
    "    zero_year = 2012\n",
    "\n",
    "    subgroup_key   = institution_table[0]['subgroup']\n",
    "    for subgroup_value in list(set([x['subgroup_value'] for x in institution_table])):\n",
    "\n",
    "\n",
    "        table_df = pd.DataFrame([x for x in institution_table if \n",
    "                                          x['subgroup'] == subgroup_key and \n",
    "                                          x['subgroup_value'] == subgroup_value])\n",
    "        table_df['year_num'] = table_df[year_key] - zero_year\n",
    "\n",
    "\n",
    "        for dv in [x for x in institution_table[0].keys() if x.find(\"_pct\")>-1]:\n",
    "\n",
    "            formula_text = formula = dv + \" ~ year_num\"\n",
    "            mod = smf.ols(formula_text, data=table_df)\n",
    "            modfit = mod.fit()\n",
    "\n",
    "            row = {\"subgroup\"      : subgroup_key,\n",
    "                   \"subgroup_value\": subgroup_value,\n",
    "                   \"min_year\"      : min([x['year'] for x in institution_table]),\n",
    "                   \"max_year\"      : max([x['year'] for x in institution_table]),\n",
    "                   \"dv\"            : dv,\n",
    "                   \"formula\"       : formula_text,\n",
    "                   \"Intercept\"     : modfit.params.Intercept,\n",
    "                   \"year_estimate\" : modfit.params.year_num,\n",
    "                   \"year_pvalue\"   : modfit.pvalues.year_num,\n",
    "                   \"year_stderr\"   : modfit.bse.year_num\n",
    "                   }\n",
    "            result_rows.append(row)\n",
    "\n",
    "    return result_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "usnews_regression_table = generate_regression_table(usnews_category_table)\n",
    "ivy_plus_regression_table = generate_regression_table(ivy_plus_table)\n",
    "hsi_hbcu_tribal_regression_table = generate_regression_table(hsi_hbcu_tribal_table)\n",
    "carnegie_regression_table = generate_regression_table(carnegie_category_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Summary and Regression Tables to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(usnews_regression_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_usnews_regression_table.csv\",\n",
    "                                             index=False)\n",
    "pd.DataFrame(usnews_category_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_usnews_summary_table.csv\",\n",
    "                                             index=False)\n",
    "\n",
    "pd.DataFrame(ivy_plus_regression_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_ivy_plus_regression_table.csv\",\n",
    "                                             index=False)\n",
    "pd.DataFrame(ivy_plus_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_ivy_plus_summary_table.csv\",\n",
    "                                             index=False)\n",
    "\n",
    "\n",
    "pd.DataFrame(hsi_hbcu_tribal_regression_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_hsi_hbcu_tribal_regression_table.csv\",\n",
    "                                             index=False)\n",
    "pd.DataFrame(hsi_hbcu_tribal_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_hsi_hbcu_tribal_summary_table.csv\",\n",
    "                                             index=False)\n",
    "\n",
    "pd.DataFrame(carnegie_regression_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_carnegie_regression_table.csv\",\n",
    "                                             index=False)\n",
    "pd.DataFrame(carnegie_category_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_carnegie_summary_table.csv\",\n",
    "                                             index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce Regression Tables for Every Institution in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................."
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "\n",
    "institution_regression_table = []\n",
    "for institution_id in set([x['UNITID'] for x in institution_years]):\n",
    "    institution_subset_rows = [x for x in institution_years if x['UNITID'] == institution_id]\n",
    "    for row in institution_subset_rows:\n",
    "        row['subgroup'] = 'institution'\n",
    "        row['subgroup_value'] = row['INSTNM']\n",
    "    regression_rows = generate_regression_table(institution_subset_rows, year_key='year_int')\n",
    "    for regression in regression_rows:\n",
    "        regression['carnegie_category'] = institution_subset_rows[0]['BASIC2018']\n",
    "        regression['usnews_category'] = institution_subset_rows[0]['usnews_category']\n",
    "        regression['ivy_plus'] = institution_subset_rows[0]['ivy_plus']\n",
    "        regression['hsi_hbcu_tribal'] = institution_subset_rows[0]['hsi_hbcu_tribal']\n",
    "    institution_regression_table += regression_rows\n",
    "    \n",
    "    if counter % 10 == 0:\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#institution_subset_rows[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 110000 regression tables for 1241 institutions.\n"
     ]
    }
   ],
   "source": [
    "print(\"Computed {0} regression tables for {1} institutions.\".format(len(institution_regression_table), \n",
    "                                                                    len(set([x['subgroup_value'] for x in institution_regression_table]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write regression tables for individual institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(institution_regression_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_institution_regression_tables.csv\",\n",
    "                                             index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Tables of Total Tenured and Tenure Track Faculty for the Article\n",
    "\n",
    "Documentation from IPEDS201213TablesDoc:\n",
    "> \"Does institution have a tenure system?\n",
    "> This variable is derived so that users can disaggregate those employees that are nontenured not on tenure track from those employees that are in an institution with no tenure system. Both EAP and Fall Staff components collect these data using 1 data  field which makes it very difficult to produce tables on tenure.  It is assumed that if all employees are reported in the nontenured not on track/no tenure system column/row, then the institution has no tenure system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tenured_Grand_total': 'tenured_Grand_total',\n",
       " 'tenured_Grand_total_men': 'tenured_Grand_total',\n",
       " 'tenured_Grand_total_women': 'tenured_Grand_total',\n",
       " 'tenured_American_Indian_or_Alaska_Native_total': 'tenured_Grand_total',\n",
       " 'tenured_American_Indian_or_Alaska_Native_men': 'tenured_Grand_total',\n",
       " 'tenured_American_Indian_or_Alaska_Native_women': 'tenured_Grand_total',\n",
       " 'tenured_Asian_total': 'tenured_Grand_total',\n",
       " 'tenured_Asian_men': 'tenured_Grand_total',\n",
       " 'tenured_Asian_women': 'tenured_Grand_total',\n",
       " 'tenured_Black_or_African_American_total': 'tenured_Grand_total',\n",
       " 'tenured_Black_or_African_American_men': 'tenured_Grand_total',\n",
       " 'tenured_Black_or_African_American_women': 'tenured_Grand_total',\n",
       " 'tenured_Hispanic_or_Latino_total': 'tenured_Grand_total',\n",
       " 'tenured_Hispanic_or_Latino_men': 'tenured_Grand_total',\n",
       " 'tenured_Hispanic_or_Latino_women': 'tenured_Grand_total',\n",
       " 'tenured_Native_Hawaiian_or_Other_Pacific_Islander_total': 'tenured_Grand_total',\n",
       " 'tenured_Native_Hawaiian_or_Other_Pacific_Islander_men': 'tenured_Grand_total',\n",
       " 'tenured_Native_Hawaiian_or_Other_Pacific_Islander_women': 'tenured_Grand_total',\n",
       " 'tenured_Nonresident_alien_total': 'tenured_Grand_total',\n",
       " 'tenured_Nonresident_alien_men': 'tenured_Grand_total',\n",
       " 'tenured_Nonresident_alien_women': 'tenured_Grand_total',\n",
       " 'tenured_Race_ethnicity_unknown_total': 'tenured_Grand_total',\n",
       " 'tenured_Race_ethnicity_unknown_men': 'tenured_Grand_total',\n",
       " 'tenured_Race_ethnicity_unknown_women': 'tenured_Grand_total',\n",
       " 'tenured_Two_or_more_races_total': 'tenured_Grand_total',\n",
       " 'tenured_Two_or_more_races_men': 'tenured_Grand_total',\n",
       " 'tenured_Two_or_more_races_women': 'tenured_Grand_total',\n",
       " 'tenured_White_total': 'tenured_Grand_total',\n",
       " 'tenured_White_men': 'tenured_Grand_total',\n",
       " 'tenured_White_women': 'tenured_Grand_total',\n",
       " 'un_tenured_Grand_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Grand_total_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Grand_total_women': 'un_tenured_Grand_total',\n",
       " 'un_tenured_American_Indian_or_Alaska_Native_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_American_Indian_or_Alaska_Native_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_American_Indian_or_Alaska_Native_women': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Asian_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Asian_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Asian_women': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Black_or_African_American_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Black_or_African_American_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Black_or_African_American_women': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Hispanic_or_Latino_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Hispanic_or_Latino_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Hispanic_or_Latino_women': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Native_Hawaiian_or_Other_Pacific_Islander_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Native_Hawaiian_or_Other_Pacific_Islander_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Native_Hawaiian_or_Other_Pacific_Islander_women': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Nonresident_alien_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Nonresident_alien_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Nonresident_alien_women': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Race_ethnicity_unknown_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Race_ethnicity_unknown_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Race_ethnicity_unknown_women': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Two_or_more_races_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Two_or_more_races_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_Two_or_more_races_women': 'un_tenured_Grand_total',\n",
       " 'un_tenured_White_total': 'un_tenured_Grand_total',\n",
       " 'un_tenured_White_men': 'un_tenured_Grand_total',\n",
       " 'un_tenured_White_women': 'un_tenured_Grand_total'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tenure_table_cols = {}\n",
    "\n",
    "for status in ['tenured', 'un_tenured']:\n",
    "    status_total_key = status + \"_\" + \"Grand_total\"\n",
    "    tenure_table_cols[status_total_key] = status_total_key\n",
    "\n",
    "    for gender in gender_groups:\n",
    "        status_gender_total_key = status_total_key + \"_\" + gender\n",
    "        #rank_gender_pct_key = rank_gender_total_key.replace(\"_Grand_total\", \"\") + \"_pct\"\n",
    "        tenure_table_cols[status_gender_total_key] = status_total_key\n",
    "\n",
    "    for demo in demo_groups:\n",
    "        demo_total_key = status + \"_\" + demo.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total\"\n",
    "        #demo_pct_key = demo_total_key.replace(\"_total\", \"_pct\")\n",
    "        tenure_table_cols[demo_total_key] = status_total_key\n",
    "\n",
    "        for gender in gender_groups:\n",
    "            demo_gender_total_key = status + \"_\" + demo.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_\" + gender      \n",
    "            #demo_gender_pct_key = demo_gender_total_key + \"_pct\"\n",
    "            tenure_table_cols[demo_gender_total_key] = status_total_key\n",
    "            \n",
    "tenure_table_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_year_summaries(record_years):    \n",
    "    record_years = [x for x in all_institution_records if x['year_int']>=2013]\n",
    "    included_years = set([x['year_int'] for x in record_years])\n",
    "\n",
    "    subgroup_table_rows = []\n",
    "    unique_denominator_keys = list(set([x for x in tenure_table_cols.values()]))\n",
    "\n",
    "    row = defaultdict(year_row)        \n",
    "\n",
    "    for institution_year in record_years:\n",
    "        year = institution_year['year_int']\n",
    "\n",
    "        ## WARNING: THIS CODE IS SOMEHOW PRODUCING 2X THE CORRECT VALUE\n",
    "        iterations = 0\n",
    "        for denominator_key in unique_denominator_keys:\n",
    "            if(institution_year[denominator_key] is not None):\n",
    "                row[year][denominator_key+\"_sum\"] += institution_year[denominator_key]\n",
    "                iterations += 1\n",
    "        assert iterations <= 2\n",
    "\n",
    "        for numerator_key, denominator_key in tenure_table_cols.items():\n",
    "            ## only add the numerator if the denominator is not None (likely rare)\n",
    "            if(institution_year[numerator_key] is not None and institution_year[denominator_key] is not None):\n",
    "                row[year][numerator_key + \"_sum\"] += institution_year[numerator_key]\n",
    "            elif(institution_year[denominator_key] is None and institution_year[numerator_key] is not None):\n",
    "                print(\"denominator key None but numerator exists!!!\")\n",
    "\n",
    "        ## calculate sum of grand totals\n",
    "#        if('tenured_un_tenured_Grand_total_sum' not in row[year].keys()):\n",
    "#            row[year]['tenured_un_tenured_Grand_total_sum'] = 0\n",
    "            \n",
    "        row[year]['tenured_un_tenured_Grand_total_sum'] += institution_year['tenured_un_tenured_Grand_total']\n",
    "\n",
    "    # patch the tenured and un-tenured sums. TODO: fix the code block starting at line 13\n",
    "    for year in included_years:\n",
    "        row[year]['tenured_Grand_total_sum'] = row[year]['tenured_Grand_total_women_sum'] + row[year]['tenured_Grand_total_men_sum']\n",
    "        row[year]['un_tenured_Grand_total_sum'] = row[year]['un_tenured_Grand_total_women_sum'] + row[year]['un_tenured_Grand_total_men_sum']\n",
    "        assert row[year]['tenured_un_tenured_Grand_total_sum'] == row[year]['tenured_Grand_total_sum'] + row[year]['un_tenured_Grand_total_sum']\n",
    "\n",
    "    for year in included_years:\n",
    "\n",
    "        zero_denominator = False\n",
    "\n",
    "        for numerator_key, denominator_key in tenure_table_cols.items():\n",
    "            try:\n",
    "                row[year][numerator_key + \"_pct\"] = (row[year][numerator_key + \"_sum\"] / row[year][denominator_key + \"_sum\"])*100.\n",
    "            except ZeroDivisionError:\n",
    "                row[year][numerator_key + \"_pct\"] = None\n",
    "                zero_denominator = True\n",
    "\n",
    "        row[year]['year'] = year            \n",
    "        row[year]['num_institutions'] = len(set([x['UNITID'] for x in record_years if x['year_int'] == year]))\n",
    "\n",
    "        ## Generate total for tenured + un_tenured\n",
    "#        row[year]['tenured_un_tenured_Grand_total'] = row[year]['tenured_Grand_total'] + row[year]['un_tenured_Grand_total']\n",
    "        \n",
    "        ## Generate demographic percentages for each year\n",
    "        for demo in demo_groups:\n",
    "            demo_total = 0\n",
    "            for status in ['tenured', 'un_tenured']:\n",
    "                demo_total_key = status + \"_\" + demo.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total_sum\"\n",
    "                demo_total += row[year][demo_total_key]\n",
    "            \n",
    "            total_key = 'tenured_un_tenured_' + demo.replace(\" \",\"_\").replace(\"/\",\"_\") + \"_total_sum\"\n",
    "            row[year][total_key] = demo_total\n",
    "            row[year][total_key.replace(\"sum\",\"pct\")] = (float(demo_total) / float(row[year]['tenured_un_tenured_Grand_total_sum'])) * 100.\n",
    "            \n",
    "\n",
    "        # skip if there's a zero denominator\n",
    "        if(zero_denominator):\n",
    "            print(\"Zero denominator: {0}: {1}\".format(year, denominator_key))\n",
    "        else:\n",
    "            subgroup_table_rows.append(row[year])\n",
    "            \n",
    "    return subgroup_table_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_summary_table = return_year_summaries([x for x in all_institution_records if x['year_int']>=2013])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[x for x in year_summary_table[0].keys() if x.find(\"_sum\")>-1]\n",
    "len(year_summary_table[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write table for year summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(year_summary_table).to_csv(data_path + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d\") + \n",
    "                                             \"_year_summary_table.csv\",\n",
    "                                             index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
